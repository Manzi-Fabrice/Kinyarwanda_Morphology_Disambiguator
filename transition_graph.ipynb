{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e86767-7dda-4f92-9ede-ac4064123c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54200832-9379-44ba-8ff2-23e3aebf7fc5",
   "metadata": {},
   "source": [
    "### Morpheme  \n",
    "\n",
    "Represents a single morpheme, the smallest unit of meaning in a word. Stores details like its type (prefix, suffix), frequency count, probability score, and whether it's the final part of a segmentation. Also includes methods to compare and hash morphemes for use in sets and dictionaries.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4efba9-ad99-4d09-aedb-1afb0dc577e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morpheme():\n",
    "    def __init__(self,morpheme:str, type, ending:bool, count:int = 1, probability:float = 0.0)->None:\n",
    "        self.morpheme = morpheme\n",
    "        self.ending = ending \n",
    "        self.count = count \n",
    "        self.type = type\n",
    "        self.probability = probability\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"morpheme: {self.morpheme}, Count: {self.count}, Probability: {self.probability:.4f}, ending: {self.ending}\"\n",
    "    def __hash__(self) ->int:\n",
    "        return hash(self.morpheme)\n",
    "    def __eq__(self, other) ->bool:\n",
    "        return isinstance(other, Morpheme) and self.morpheme == other.morpheme\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bf213-825b-4af8-aa70-4b9c0203898d",
   "metadata": {},
   "source": [
    "### GraphNode  \n",
    "\n",
    "Represents a node in the transition graph. Each node holds a set of morphemes that can appear at a specific position in a word segmentation. Helps organize morphemes based on their position in the structure.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28514bc8-d18e-455f-812f-3a0d4238cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNode():\n",
    "    def __init__(self,index:int) ->None:\n",
    "        self.index = index\n",
    "        self.morphemes = set() \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ef4d1-eec2-42e3-80f8-c24a99225a03",
   "metadata": {},
   "source": [
    "### TransitionGraph  \n",
    "\n",
    "Handles building and managing the transition graph for morphological segmentation. Reads the segmentation file, processes morphemes, and constructs a structure for generating possible inflected forms. Also normalizes morpheme probabilities and retrieves valid segmentations from the graph.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9720ff-d3e3-41ad-86fb-53549fc22c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionGraph():\n",
    "    def __init__(self, inputFile:str)->None:\n",
    "        self.graph =  []\n",
    "        self.starting_node = [] \n",
    "        self.morpheme_index_mapping = {}\n",
    "        self.morpheme_count = 0 \n",
    "        self.build_transition_graph(inputFile)\n",
    "        \n",
    "    def build_transition_graph(self, inputFile:str)->None:\n",
    "        if inputFile == None:\n",
    "            raise ValueError(\"Please provide a valid input file path \")\n",
    "        try:\n",
    "            with open (inputFile, \"r\") as segmentations:\n",
    "                for line in segmentations:\n",
    "                    if line[0] == '+':\n",
    "                        self.process_segmentation(line)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Error: The file '{inputFile}; was not found,\")\n",
    "        except IOError:\n",
    "            raise IOError(f\"Error: Colud not read the file '{inputFile}'\")\n",
    "        \n",
    "        for node in self.graph:\n",
    "            self.normalize(node)\n",
    "            \n",
    "    def process_segmentation(self, segmentation: str)->None:\n",
    "        root_processed = False\n",
    "        segments = segmentation[1:].split(\"+\")\n",
    "        for idx, segment in enumerate(segments):\n",
    "            node = GraphNode(idx)\n",
    "            valid_morpheme = segment if segment.isupper() else 'root' \n",
    "            real_morpheme = valid_morpheme[:-1] if valid_morpheme[-1] =='\\n' else valid_morpheme\n",
    "            appending = Morpheme(\n",
    "                morpheme = real_morpheme,\n",
    "                type = \"prefix\" if not root_processed else \"suffix\",\n",
    "                ending = (idx==len(segments)-1),\n",
    "                count =1,\n",
    "                probability = 0.0\n",
    "                )\n",
    "            if real_morpheme =='root':\n",
    "                root_processed = True \n",
    "            if idx < len(self.graph):\n",
    "                if appending in self.graph[idx].morphemes:\n",
    "                    for existing in self.graph[idx].morphemes:\n",
    "                        if existing ==appending:\n",
    "                            existing.count += 1 \n",
    "                else:\n",
    "                    self.graph[idx].morphemes.add(appending)\n",
    "            else:\n",
    "                # if index not present create a new_node\n",
    "                new_node = GraphNode(idx)\n",
    "                new_node.morphemes.add(appending)\n",
    "                self.graph.append(new_node)\n",
    "    def normalize(self, node) ->None:\n",
    "        if not node or not node.morphemes:\n",
    "            return \n",
    "        counts = [morpheme.count for morpheme in node.morphemes]\n",
    "        \n",
    "        if not counts or max(counts)==0:\n",
    "            return \n",
    "            \n",
    "        max_count = max(counts) \n",
    "        scaled_counts = np.array(counts) / (max_count + 1)\n",
    "        exp_counts = np.exp(scaled_counts - np.max(scaled_counts))\n",
    "        total_exp = np.sum(exp_counts)\n",
    "        \n",
    "        probabilities = exp_counts / total_exp\n",
    "        \n",
    "        for idx, morpheme in enumerate(node.morphemes):\n",
    "            morpheme.probability = probabilities[idx]\n",
    "    def get_inflection(self, root)->set:\n",
    "        inflection = []\n",
    "        # start with the root and expand to all possible inflections \n",
    "        self.get_inflection_helper(root, \"\", 0, inflection, False)\n",
    "        return set(inflection)\n",
    "\n",
    "    def get_inflection_helper(self, root, current: str, index: int, morphemes: list, root_processed: bool):\n",
    "        if len(current.split(\"+\"))>=8: \n",
    "            return \n",
    "        if len(morphemes) > 1000:\n",
    "            return \n",
    "        \n",
    "        if index >= len(self.graph):\n",
    "            if root_processed:\n",
    "                morphemes.append(current)\n",
    "            return \n",
    "    \n",
    "        candidates = sorted(self.graph[index].morphemes, key=lambda morpheme:morpheme.probability)[:5] if index > 2 else self.graph[index].morphemes\n",
    "        for candidate in candidates:\n",
    "            new = \"\"\n",
    "            temp_root_processed = root_processed\n",
    "            if candidate.morpheme ==\"root\" and not root_processed:\n",
    "                new = current + \"+\" + root \n",
    "                temp_root_processed = True \n",
    "            else:\n",
    "                if not root_processed and candidate.type ==\"prefix\":\n",
    "                    new = current + \"+\" + candidate.morpheme if candidate.morpheme not in current.split(\"+\") else \"\"\n",
    "                elif root_processed and candidate.type == \"suffix\":\n",
    "                    new = current + \"+\" + candidate.morpheme if candidate.morpheme not in current.split(\"+\") else \"\"\n",
    "\n",
    "            if candidate.ending and root_processed and len(new)> 0:\n",
    "                morphemes.append(new)\n",
    "            else:\n",
    "                next = new if len(new) > 0 else current\n",
    "                self.get_inflection_helper(root, next, index+1, morphemes, temp_root_processed)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403dce5-06fb-4c3e-ad1f-6c07c3a167db",
   "metadata": {},
   "source": [
    "#### Testing:  \n",
    "\n",
    "Testing the segmentation system by building the transition graph and generating inflections for a sample word. This will check if morphemes are processed correctly and if the graph structure makes sense. Printing a few nodes to verify everything looks good.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d57511bd-0e25-4970-a271-4f7d612a3a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Building TransitionGraph from segmentation.txt\n",
      "Graph built with 12 nodes.\n",
      "\n",
      "  Generating inflections for 'sura'\n",
      "Generated 135 Inflections for 'sura'. Showing first 10:\n",
      "['+V+CL16+HAB.PAST+OBJ.CL11+sura+RECIP+LOC', '+V+CL16+HAB.PAST+OBJ.CL15+sura+BEN+IMP', '+V+CL16+HAB.PAST+OBJ.1PL+sura+RECIP+LOC', '+V+CL16+HAB.PAST+OBJ.CL10+OBJ.1PL+sura+PERF', '+V+CL16+HAB.PAST+OBJ.CL10+OBJ.CL15+sura+IMP', '+V+CL16+HAB.PAST+OBJ.1PL+sura+root+PERF', '+V+CL16+HAB.PAST+OBJ.CL15+sura+root+IMP', '+V+CL16+HAB.PAST+OBJ.CL10+OBJ.CL11+sura+IMP', '+V+CL16+HAB.PAST+OBJ.CL11+sura+PERF', '+V+CL16+HAB.PAST+OBJ.CL15+sura+BEN+PERF']\n",
      "\n",
      " Checking individual graph nodes and morphemes\n",
      "\n",
      "Node 0: Showing 3 morphemes\n",
      "- morpheme: V, Count: 45957, Probability: 0.5758, ending: False\n",
      "- morpheme: ADJ, Count: 2, Probability: 0.2119, ending: False\n",
      "- morpheme: N, Count: 103, Probability: 0.2123, ending: False\n",
      "\n",
      "Node 1: Showing 3 morphemes\n",
      "- morpheme: CL16, Count: 634, Probability: 0.0297, ending: False\n",
      "- morpheme: CL13, Count: 773, Probability: 0.0304, ending: False\n",
      "- morpheme: 2PL, Count: 529, Probability: 0.0292, ending: False\n",
      "\n",
      "Node 2: Showing 3 morphemes\n",
      "- morpheme: CL16, Count: 34, Probability: 0.0227, ending: False\n",
      "- morpheme: CL13, Count: 85, Probability: 0.0228, ending: False\n",
      "- morpheme: 2PL, Count: 71, Probability: 0.0227, ending: False\n",
      "\n",
      "Node 3: Showing 3 morphemes\n",
      "- morpheme: OBJ.CL7, Count: 1369, Probability: 0.0238, ending: False\n",
      "- morpheme: BEN, Count: 35, Probability: 0.0189, ending: False\n",
      "- morpheme: REFL, Count: 2120, Probability: 0.0272, ending: False\n",
      "\n",
      "Node 4: Showing 3 morphemes\n",
      "- morpheme: BEN, Count: 1162, Probability: 0.0246, ending: False\n",
      "- morpheme: OBJ.CL7, Count: 848, Probability: 0.0241, ending: False\n",
      "- morpheme: REFL, Count: 3480, Probability: 0.0286, ending: False\n"
     ]
    }
   ],
   "source": [
    "segmentation_file = \"segmentations.txt\"\n",
    "\n",
    "print(\"\\n Building TransitionGraph from segmentation.txt\")\n",
    "graph = TransitionGraph(segmentation_file)\n",
    "print(f\"Graph built with {len(graph.graph)} nodes.\")\n",
    "\n",
    "test_root = \"sura\"\n",
    "\n",
    "print(f\"\\n  Generating inflections for '{test_root}'\")\n",
    "inflections = graph.get_inflection(test_root)\n",
    "\n",
    "print(f\"Generated {len(inflections)} Inflections for '{test_root}'. Showing first 10:\")\n",
    "print(list(inflections)[:10])  \n",
    "\n",
    "print(\"\\n Checking individual graph nodes and morphemes\")\n",
    "for i, node in enumerate(graph.graph[:5]):  \n",
    "    print(f\"\\nNode {i}: Showing 3 morphemes\")\n",
    "    for morpheme in list(node.morphemes)[:3]: \n",
    "        print(f\"- {str(morpheme)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882eb91-ca59-4cf3-9df1-3741be6b0d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
